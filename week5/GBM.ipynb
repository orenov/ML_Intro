{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497009</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>0.585445</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.803455</td>\n",
       "      <td>0.106105</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.480124</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209791</td>\n",
       "      <td>0.610350</td>\n",
       "      <td>0.356453</td>\n",
       "      <td>0.517720</td>\n",
       "      <td>0.679051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.196344</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.235606</td>\n",
       "      <td>0.288764</td>\n",
       "      <td>0.805110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.517794</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494734</td>\n",
       "      <td>0.781422</td>\n",
       "      <td>0.154361</td>\n",
       "      <td>0.303809</td>\n",
       "      <td>0.812646</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
       "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
       "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
       "2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
       "3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
       "4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
       "\n",
       "         D8        D9  ...    D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
       "0  0.585445  0.743663  ...        0      0      0      0      0      0      0   \n",
       "1  0.411754  0.836582  ...        1      1      1      1      0      1      0   \n",
       "2  0.517720  0.679051  ...        0      0      0      0      0      0      0   \n",
       "3  0.288764  0.805110  ...        0      0      0      0      0      0      0   \n",
       "4  0.303809  0.812646  ...        0      0      0      0      0      0      0   \n",
       "\n",
       "   D1774  D1775  D1776  \n",
       "0      0      0      0  \n",
       "1      0      1      0  \n",
       "2      0      0      0  \n",
       "3      0      0      0  \n",
       "4      0      0      0  \n",
       "\n",
       "[5 rows x 1777 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"gbm-data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = data['Activity']\n",
    "data.drop('Activity', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, \n",
    "                                      test_size=0.8, \n",
    "                                      random_state=241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.0190            1.10m\n",
      "         2           0.9192           55.30s\n",
      "         3           0.8272           48.25s\n",
      "         4           0.7834           44.90s\n",
      "         5           0.7109           43.14s\n",
      "         6           0.6368           42.23s\n",
      "         7           0.5797           41.53s\n",
      "         8           0.5610           40.35s\n",
      "         9           0.5185           40.39s\n",
      "        10           0.4984           40.22s\n",
      "        20           0.1999           36.39s\n",
      "        30           0.1313           33.54s\n",
      "        40           0.0790           32.16s\n",
      "        50           0.0511           30.67s\n",
      "        60           0.0352           28.77s\n",
      "        70           0.0245           27.19s\n",
      "        80           0.0162           25.64s\n",
      "        90           0.0114           23.99s\n",
      "       100           0.0077           22.62s\n",
      "       200           0.0004            6.74s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1255           58.01s\n",
      "         2           1.0035            1.18m\n",
      "         3           0.9386            1.08m\n",
      "         4           0.8844           57.30s\n",
      "         5           0.8381           53.18s\n",
      "         6           0.7995           53.07s\n",
      "         7           0.7559           53.95s\n",
      "         8           0.7205           54.38s\n",
      "         9           0.6958           52.44s\n",
      "        10           0.6725           51.03s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-42344f879fd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlearning_rates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m241\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mscores_train_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstaged_predict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mscores_test_raw\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstaged_predict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/oleksiirenov/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, monitor)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_score_to_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/oleksiirenov/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, monitor)\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, random_state,\n\u001b[0;32m--> 783\u001b[0;31m                                     begin_at_stage, monitor)\n\u001b[0m\u001b[1;32m    784\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/oleksiirenov/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, random_state, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0;31m# fit next stage of trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_mask,\n\u001b[0;32m--> 835\u001b[0;31m                                      criterion, splitter, random_state)\n\u001b[0m\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/oleksiirenov/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_mask, criterion, splitter, random_state)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             tree.fit(X, residual,\n\u001b[0;32m--> 572\u001b[0;31m                      sample_weight=sample_weight, check_input=False)\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/oleksiirenov/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_mask, X_argsorted, check_input, sample_weight)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rates = [1, 0.5, 0.3, 0.2, 0.1] \n",
    "results = {}\n",
    "for learning_rate in learning_rates:\n",
    "    clf = GradientBoostingClassifier(n_estimators=250, learning_rate=learning_rate, verbose = True, random_state=241)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores_train_raw = clf.staged_predict_proba(X_train)\n",
    "    scores_test_raw  = clf.staged_predict_proba(X_test)\n",
    "    scores_test = []\n",
    "    scores_train = []\n",
    "    for i,scores in enumerate(scores_test_raw):\n",
    "        ll = log_loss(y_test, scores[:,1])\n",
    "        scores_test.append({'n_iter' : i, 'log_loss' : ll})\n",
    "        \n",
    "    for i,scores in enumerate(scores_train_raw):\n",
    "        ll = log_loss(y_train, scores[:,1])\n",
    "        scores_train.append({'n_iter' : i, 'log_loss' : ll})\n",
    "    \n",
    "    results[learning_rate] = {'scores_test' : scores_test, 'scores_train' : scores_train}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charts log_loss | Learning rate = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1215a7c10>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEACAYAAAC57G0KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYXHWZ9vHvTRJI2AyLgCRAQBDBDTcWFQwuGHDBBeVF\n",
       "4RVxYXRwm3HGkdexUjqOo6OjDM4gAoKgLzDjgrihIoZRVsMOCUuACEkgLAlrAiTkmT+e03SlU91d\n",
       "6a6qU8v9ua66qqvqVJ2niuKuk9/5LYoIzMys92xQdgFmZtYaDngzsx7lgDcz61EOeDOzHuWANzPr\n",
       "UQ54M7MeNWrAS/qepKWSbhjm8fdJuk7S9ZIukfTi5pdpZmbrq5Ej+NOBWSM8fgdwQES8GPgS8N1m\n",
       "FGZmZuMzasBHxB+B5SM8fllEPFzcvAKY3qTazMxsHJrdBv9B4FdNfk0zMxuDic16IUkHAscAr27W\n",
       "a5qZ2dg1JeCLE6unALMiom5zjiRPemNmNgYRobE8b9wBL2lH4CfAkRGxYKRtx1pkr5E0OyJml11H\n",
       "J/BnMcifxSB/FoPGc3A8asBLOht4LbC1pLuBCjAJICJOBr4AbAGcJAlgVUTsPdaCzMysOUYN+Ig4\n",
       "YpTHPwR8qGkVmZlZU3gkaznmlF1AB5lTdgEdZE7ZBXSQOWUX0AvUrgU/JIXb4M3M1s94srNp3STN\n",
       "zBrhHnXDa/ZBsAPezNrO/5pfVyt++NwGb2bWoxzwZmY9ygFvZtajHPBmZj3KAW9mVpC0UNLrxvka\n",
       "R0v6Y7NqGg8HvJnZoAB6poePA97MDJB0FrAj8HNJj0r6jKR9JV0qabmkayW9tmb7oyXdLukRSXdI\n",
       "eq+k5wPfAfYrXmNZWe8HPJLVzNpsxCxoZl/wMeSNpDuBD0bERZKmAdeRM+VeIOkNwDnA7sATwBLg\n",
       "FRFxm6Rtga0iYp6k9wMfioj913PfdT+X8WSnj+DNzOo7EvhVRFwAEBEXAnOBN5NNOWuAF0maEhFL\n",
       "I2Je8byOOZB1wJtZ54hQ0y7jtxPw7qJ5Zrmk5eSKddtFxArgcOCvgCWSfiFp9ybss6kc8GZmg2qb\n",
       "iO4CzoqILWoum0XE1wAi4rcRcRCwHXAzuard0NcolQPezGzQUuC5xd8/BN4q6SBJEyRNljRT0jRJ\n",
       "20g6VNImwCrgceDpmteYLmlS+8tfmwPezGzQV4DPF80x7wYOBY4H7iOP6P+WbGPfAPg0sBh4ENgf\n",
       "+GjxGr8HbgLulXRfW6sfwr1ozKytnAX1uReNmZk1zAFvZtajHPBmZj3KAW9m1qMc8GZmPcoBb2bW\n",
       "oxzwZmY9ygFvZtajHPBmZk0i6SRJny+7jgEeyWpmbdXJWSBpIXBMRFxUwr7bP5JV0vckLZV0wwjb\n",
       "/Luk2yRdJ+mlYynEzKwDDLtkn6SJba5l3BppojkdmDXcg5IOAXaNiN2AjwAnNak2M7O2qbNk399J\n",
       "WiPpGEl/AS4stvtvSfdIekjSxZL2rHmNMyR9qfh7pqRFkv6mOEheIunodr6nUX+RIuKPkmaMsMnb\n",
       "gO8X214haaqkbSNiaXNKNLN+oWrzluyLyvo1a0TEUZJew+CSfTsBXwUOAJ5PruAE8EvgaOAp4Gvk\n",
       "tMIDLRfB2vPBbwtsDmwPHAT8SNJPI+LhMb2p9dSMk6zTgLtrbi8Cpjfhdc3MyjTwAzE7IlZGxJMA\n",
       "EXFGRDweEauAKvASSZvVeR7kXPFfjIinI+LXwGPkmq7D7FHbIM1E+hjSt5FePp430Kw2paG/lB2z\n",
       "oomZdY/1Pepuk2cOYCVtAPwzcBjwbAaP6rcGHq3z3AcjYk3N7RXAps/ckgQcCBxT3DO05ePW8RTe\n",
       "jIBfDOxQc3t6cd86JM2uuTknIuY0Yf9mZs1S7+C09r73kc3Sr4+Iv0iaCixj7YPcEQ9wNwCQ9iUX\n",
       "E3kdsHfNw4/8HBb9BJ5cDvfPz6ahMWtGwJ8PHAecoyz6oeHa3yNidhP2Z2bWKgNL9g3XTXJT4Elg\n",
       "WbFc3z8PeVzU64UjbQW8cyvY8kw4k2zaHrAM+HdgNjD1rRHx1rWeqo8yRo10kzwbuBTYXdLdxRnl\n",
       "YyUdCxARvwLukLQAOBn42FiLMTMr2cCSfcuAd7Hu0fiZwF/IVoobgcuGbDP0JGsgHQbMA767GWw+\n",
       "OcN9KfBN4J3ADCKquXVzByZ5oJOZtVVfZIH0MuBw4A3Ay4p7/0T2wPkjcAURq9d+SvMHOnVdx30z\n",
       "s44kvRb4PHkesrbt/D6y+eVk1j7h2nIOeDOz0eQo1qlEPFD0fDkEeA/wIrJJZjNgt5pnPA6cCvwB\n",
       "uJCIx9tcMeCANzNblzSFbF7Zn+y3fgAwFekeYAKwTZ1nPUm24f8UWEjEI22qdlgOeDOzAdIE4Ejg\n",
       "y6zd0wVgJfCc4u97gROAi4HVZP/2O4lY0aZKG+KAN7P+Je1FNrfsQwb65gw2tdwInAfcAFwD3A7M\n",
       "IEen3jP0JGkncsCbWf/JCcL+BXhrnUfvBv4f8MM6J0XvaHVpzeRukmbWVlLzJhTrNe4maWZdre0H\n",
       "ejmdwD8BH2VwcOejwNlAlYglba2njRzwZtZbshvjQcBbgFcAewGTgaeBbwHnAtd32gnRVnDAm1n3\n",
       "kp4FHEvOuz6ZnEdmT9aeABGyt8sniLi+vQWWywFvZp1DmgzsRx51TwFuIkeC7khOzftzYEOyt8th\n",
       "5MjRreq80hLgFOAS4GoiHmx57R3IAW9m5cv+58cDnyODfThPkEfqtf4H+AXZffH24nJrN3RjbDUH\n",
       "vJmVR9oN+AbwSmC74t5rgcvJgUV7kEfo95L91F9GhvwysjvjPwG/bPYsjL3CAW9m7ZXTALyAXPDi\n",
       "UwyucLQEOJqI3w3zPJErJy0j4uk2VNr13A/ezFovp899OfA8cs2IjWse/W+yeWahm1XW5X7wZtaZ\n",
       "pM3JCbiGLgR0M9kM833gYjextIYD3syaJ0+W7kNOo/s84N1kl8XV5JH6w8DpRFxZWo19xAFvZuOT\n",
       "of4acn70d5F90mvNBT7Yb33QO4ED3swalyc6dyYXuNgZeD3ZH327mq1uJ5enu4WckfHXblsvhwPe\n",
       "zIaXgb4/OU3uPuTUujPqbHknOQXAfwHXuk29Mzjgzaw+6fnAieTKRrUeILs03k+eKD0PuMqh3nkc\n",
       "8GaWsivjYcDewBbASwEBDwIXAAuAXwFz2714tI2NA96sn+RcL68mA3w6GeYHAhsV99V6Cjgd+AIR\n",
       "97WzTGsOB7xZL5M2A95LLhT9crKXy7OG2foh4AfAhcBS4HYi7m9HmdYaDnizXiXtQraPv2jII9eR\n",
       "PV3uA+YBvwWWAw8R8VRba7SWcsCb9ZI8Mfp2clKutwOTgFvJGRcXA+cQcXN5BVo7OeDNeoG0I3AS\n",
       "2Y1xwBrgh8DHiVheSl1WKge8WbfKEaQDR+qfIifwehT4EXApMIeIBeUVaGVzwJt1ixx0tBt5snQF\n",
       "UAVeUrPFfwGfJOLeEqqzDjRqwEuaRS5UOwE4NSK+OuTxrckz79sVr/f1iDij+aWa9amckfHL5JH6\n",
       "9CGPLgF+B3yXiEvbXZp1thHng1f+E/AWciTbYuDPwBERMb9mm9nARhHxuSLsbwG2jSFzT3g+eLMR\n",
       "SBOB5wC7kL1e9iRXNHocOALYtdjyAeAyYCpwFfCPRDzW9nqtbVo5H/zewIKIWFjs6BxyFZb5Ndvc\n",
       "A7y4+Htz4MGh4W5mdWSTyx7AUcBfkaE9nOuBD5FTAngUqTVktICfRq57OGAROeFQrVOAiyQtIWeY\n",
       "e0/zyjPrIdIGZJv5W4GDyXCvHXR0L/AXcgbGm8jRpZsWt39GxMq21mtdb7SAb2TyoOOBayNipqTn\n",
       "Ar+T9JKIeHTohkVzzoA5ETGn4UrNukUemW9PTqV7MLAfsCV5ADTU/eT8Lt8h4vK21WgdS9JMYGYz\n",
       "Xmu0gF9MrsYyYAfyKL7Wq8gTQETE7ZLuBHYnJ/lfS0TMHnOlZt1AOhz4DsM3tywmA/18cibGBz0L\n",
       "o9UqDnznDNyWVBnra40W8HOB3STNIM/WH06e8Kl1M3kS9hJJ25LhfsdYCzLrWtILyMm5ppBD/68A\n",
       "fk32clkCPEbE0+UVaP1mxICPiNWSjgN+Q3aTPC0i5ks6tnj8ZOCfgdMlXQdsAPx9RCxrcd1mnSXD\n",
       "/edkuH+fiKPLLchslG6STd2Ru0lat8tuw9uTi0m/hey6OI3sm/7sYqurgJnuumjN0spukmb9S9oU\n",
       "2IkcxLcn8HesfU6q1mrgLOA4Ila0p0CzkTngzWrlyO3jgBeS4T7UA2TX4d8AV5KdDhYB97l93TqN\n",
       "A976V87A+ElyCoCtyfnRd63Z4ilgITmY7x6y58u5Hmhk3cIBb/1B2hj4CNl+vgnwGnJagFqbA6uA\n",
       "2cBPgAV4VLZ1MQe89a7s2XIMsD/wXHKwUa1HyW6M3wRuA3YElhKxpJ1lmrWKe9FY78ipAPYip9Td\n",
       "kezCW3sQcxU58+mTZB/169xubp3OvWis/0g7Ae8jx17cSja5vAfYdsiWpwNnknO8LPSoUesnDnjr\n",
       "HtIk4G3Ah4GDgHpHNXcBVwOTgTOIOLd9BZp1Fge8dS5pZ3Kirt3JOdIPZHCOlyeBHwOPkN0Z55K9\n",
       "XK7yUbpZcsBbZ8lQ34Nclu4LrPsdvYmcovoHRDzY5urMuooD3sohTSbbzd9EjhLdFJhBnhyt9Qty\n",
       "sYtbgD8R4YnszBrkgLfmkLYn52nZhvxeLSOH+D8E3Am8APg02fd8Y3Khi0l1XulhcmnIFeQc6b9u\n",
       "ee1mPcoBb2MjbUI2o+wA/F/ypOf6uo4c8n8p8Bh5gvRODy4yaw4HvDVOeg7Zg+UtwEtZ+/vzODlY\n",
       "6D7gaWArcgm6bcjFpB8iJ+P6SbHtY56Uy6y1HPCWpKnkEflKYCl5ZH50cb0pGdQzap6xBriGDPX5\n",
       "wIk+6WnWWRzw/UyaAnwGOIzshjjaaLkngAuA75InPNdZd9fMOocDvl9JBwH/Sc7RAjnJ1lXkd2Kr\n",
       "4vZ/AReT7eMPAbcTsar9xZrZWDjge02e/HwRObHWA+Qw/ofJIfyvIIfzH8DgXOc3kQtZzCFiZdvr\n",
       "NbOWccD3Emk/4KesOx/L0+SaurUeBb4M/JuPys16kwO+V0hHAacCG5InPheS64Q+n5yXZTkwD/gt\n",
       "2ZNlvmdSNOttDvhuJO0JvJbsybIn8EpyzhaA/wA+/cxRuTQRmEDEkyVUamYlcsB3Omlzst18T7I7\n",
       "4mHUH1T0FPApIk5a694cNOSBQ2Z9yAHfSXJ+lklkm/mzyWA/nsEZFAesJNvanwBuJ4f2zyViefuK\n",
       "NbNO54DvBNkf/QvA31J/fpZLgDnAC4HLge8Ssaxt9ZlZV3LAlyW7Mx4MvAt4M7BZ8cjjZI+XFWSw\n",
       "fwf4tec4N7P15YBvB2kCOS3u+8jpADYDtgCm1Gz1Z+CTRFzW/gLNrBc54NdXLuz8cnJulivJUZ7P\n",
       "I6e/vYqIx4vttgU+QLanv5+cLneoy8lViX7iec7NrNkc8I3Ik59HFZcXse5JzwFPI10N/Al4O7Bz\n",
       "zWN3ASeR0+PeDzxBxAMtq9nM+p5Ga9qVNAv4FtkufGpEfLXONjOBb5InCB+IiJl1tomIGG0yq3JI\n",
       "LwCmkT1S9iYXrtiOXJxia3KI/8Y1z/gLGdgvIwcW3U3O1fIS1h4xejV5lD8fONl90c1sfY0nO0cM\n",
       "eGXb8S3AG4DFZDvxERExv2abqeTJwDdFxCJJW0edI9OOC3hpa2AW8FHgVQ08Yy5wAvB74N66Jz2l\n",
       "zYB9gf3J0aNfJOKxZpVsZv1nPNk5WhPN3sCCiFhY7Ogc4FDyiHTAe4EfR8QigHrh3hHyh+hIcsTn\n",
       "PgzOogjwCDmMf1dyRsX55ERdC4AHgXlELBl1Hzl97u+Ki5lZqUYL+Glk88OARWQ41toNmCTpD2Tv\n",
       "kBMi4qzmlThG0rOB15NNJhOBCmu3ia8k/0XyA+BsH2mbWa8ZLeAb6Xs9iWyLfj3ZTn2ZpMsj4rah\n",
       "G06R/umJwWHzcyJizvoU2xDpucDfAMeQzSS1riEXq7gCuNGzKJpZpynOac5sxmuNFvCLySXbBuxA\n",
       "HsXXups8sboSWCnpf8iTjesE/Eq4iIiLxlFvfTkS9O1kqL+ewZWJfk+uEboBeS7hK0Q80fT9m5k1\n",
       "SXHgO2fgtqTKWF9rtICfC+wmaQawBDgcOGLINj8Dvl2ckN2IbML5t2Fe70Bg7AGf+ziwuDWPXNT5\n",
       "bcCJwPTi/ieBc4B/JeKmMe/LzKzLjRjwEbFa0nFk3+0JwGkRMV/SscXjJ0fEzZIuAK4np689JSLm\n",
       "DfOSrwP+saHKpF3IybaeBA4hBxJtQs6qOGAZuXIRxf5PJtvTPemWmfW9UfvBN21HUkS2v28x6glN\n",
       "aTuynXzHOo/eBdxJ9vCZQjYRfQP4thewMLNe08puks02kZwxsbrOI9n8ciTwCbK74ubAdeRAoT+T\n",
       "a4tuSU689UTR7r4DsICINW2p3sysi7T7CH4NecKzCvwL2ezzTuBS4GvF3wNuAl5HxH1tKdDMrAO1\n",
       "bCRrM0mKxyfy8Y1Xc2Jx1wPkKkTbk90xRQ73/yRwIbDUTS5m1u/GE/AbNLuYkWzyec4nuzFeT87x\n",
       "sj3Zhi4y7A8l4kwiljjczczGp91t8DsScRHSXsAe5IReF5MDpZ4k4vo212Nm1rPaH/BAMVHXvOIC\n",
       "eRLVzMyaqK1NNMBObd6fmVnfanfA1+vXbmZmLeCANzPrUQ54M7Me1fY2eFXVOas6mZn1sHYH/Gbk\n",
       "pGFmZtZi7Q54cDONmVlblBHwu5WwTzOzvlNGwO9bwj7NzPqOA97MrEeVEfCvUFUblrBfM7O+0u6A\n",
       "vxWYTC7KbWZmLdTugL+suN6vzfs1M+s77Q74S4vr17R5v2ZmfafdAf+H4vp1qqqM9n8zs77R7pBd\n",
       "ANwFbIXb4c3MWqqtAR+VCHK9VYA3tHPfZmb9poxmEge8mVkblBHwFxXXB6iqjUvYv5lZX2h7wEcl\n",
       "lpJrsE4G3tju/ZuZ9YuyerKcV1y/vaT9m5n1vLIC/mfF9VtV1cSSajAz62mjBrykWZJulnSbpM+O\n",
       "sN0rJa2W9M4G9juP7DK5FR70ZGbWEiMGvKQJwLeBWcCewBGS9hhmu68CFwCjLslXdJf87+LmUetZ\n",
       "s5mZNWC0I/i9gQURsTAiVgHnAIfW2e7jwI+A+9dj398vrt+jqjZZj+eZmVkDRgv4acDdNbcXFfc9\n",
       "Q9I0MvRPKu6KRnYclbgFuBzYFHhHI88xM7PGjXaCs5Gw/hbwDxERksQITTSSZtfcnMNsziAXADkS\n",
       "+EED+zIz62mSZgIzm/JaEcNnuKR9gdkRMau4/TlgTUR8tWabOxgM9a2BFcCHI+L8Ia8VEbFW+Kuq\n",
       "rYF7yR+SbaMSy8b/lszMeke97GzUaE00c4HdJM2QtCFwOLBWcEfELhGxc0TsTLbDf3RouA8nKvEA\n",
       "OcPkROq37ZuZ2RiNGPARsRo4DvgN2bXx3IiYL+lYScc2qYYfFdeHNen1zMyMUZpomrqjYf6Zoaq2\n",
       "Ae4B1gDTi6kMzMyM1jbRtFxU4j7gF2QzzTEll2Nm1jNKD/jCQBfLj6iqCaVWYmbWIzol4H8LLARm\n",
       "4D7xZmZN0REBH5VYA/xrcfMbnifezGz8OiLgCycD1wI7AseXXIuZWdcrvRfNWttU9SrgEuAp4IVR\n",
       "idvaUpyZWYfq6l40taISlwKnAxsCJ5RcjplZV+uogC/8A/AYcLCq2q3sYszMulXHBXzRL/7Hxc0j\n",
       "yqzFzKybdVzAF84urt+rqsbU9mRm1u86NeB/Ty4esjuwX8m1mJl1pY4M+KjEauCM4uZZqmqLEssx\n",
       "M+tKHRnwhQpwNbALcIabaszM1k/HBnxUYiXwLuBh4G3AR8qtyMysu3TUQKe6z6vqcHKx7xXArlGJ\n",
       "e5penJlZh+qZgU71RCXOBX4GbIynMDAza1jHB3zh8+S6rceqqp3LLsbMrBt0RcBHJW4EfghMAk72\n",
       "CVczs9F1RcAXPgM8CLwR+FjJtZiZdbyuCfhirdaPFzdPVFUfLLMeM7NO1zUBDxCVOJs80SrgFFU1\n",
       "q+SSzMw6VlcFPEBU4ivAF8mQP1tV7VVySWZmHanrAr5QJbtOTgUuVVVvKbkeM7OO0/EDnYZ9vaom\n",
       "AycBRwPLgOdHJe5v1uubmXWCnh7oNJyoxBPAMcDvgC2BE1RV174fM7Nm69oj+Gdet6pdgRuBjYBL\n",
       "gXcUi4aYmXW9vjyCHxCVWAC8A7gXeBXw9XIrMjPrDF1/BP/M61f1XGAeuWD33lGJP7dqX2Zm7dLy\n",
       "I3hJsyTdLOk2SZ+t8/j7JF0n6XpJl0h68ViKGY+oxO3At4qb3/R0BmbW70YNeEkTgG8Ds4A9gSMk\n",
       "7TFkszuAAyLixcCXgO82u9AGfRm4D3g18O6SajAz6wiNHMHvDSyIiIURsYqcm/3Q2g0i4rKIeLi4\n",
       "eQUwvbllNiYq8Qjwj8XNf/VSf2bWzxoJ+GnA3TW3FxX3DeeDwK/GU9Q4nQZcBewI/EhVbVZiLWZm\n",
       "pWkk4Bs+CyvpQLJv+jrt9O0SlXgaeCewFHgdsFhVfUlVTSmrJjOzMkxsYJvFwA41t3cgj+LXUpxY\n",
       "PQWYFRHL672QpNk1N+dExJyGK10PUYm7VNVB5LmD/ckFQw5XVQcXJ2PNzDqSpJnAzKa81mjdJCVN\n",
       "BG4BXg8sAa4EjoiI+TXb7AhcBBwZEZcP8zot7SY5HFX1KuBk4IVkX/nXRiVubXcdZmZjMZ7sbKgf\n",
       "vKSDyS6IE4DTIuIrko4FiIiTJZ1KDja6q3jKqojYu1lFjlfRDn8e2WRzA7BPVGJlGbWYma2Plgd8\n",
       "M5QZ8PBMyM8Fngf8EvhIVGJJWfWYmTXCAd9oDVW9BPgTsCmwGvgD8FdRiTvKrMvMbDh9PRfN+ohK\n",
       "XEe2xf+UfO9vBM5VVZNKLczMrAX66gi+lqrahjxhvBPwTeBvo9KmD8PMrEE+gh+DYkrho4E1wKeB\n",
       "n6mqF5ValJlZE/XtEfwAVfVm4P8Dmxd3nQJ8ppj2wMysVD6CH4eoxC+BF5ODop4CPgxcpapeUGph\n",
       "Zmbj1PdH8LVU1QuBH5KBvxL4GnBiVOLBUgszs77lbpJNpKo2IRfzPqq46yngfOCkqMRFpRVmZn3J\n",
       "Ad8Cqmp/4HjgIAabsj4VlTihvKrMrN844FtIVU0D/hr4XHHX/wBfj0r8vLyqzKxfOODbQFV9GDgR\n",
       "2IicQvkTwH+477yZtZIDvk1U1bOATwGzi7vOI9vrL3e3SjNrBQd8m6mqo4D/AAZWi1oDXA2cC5wd\n",
       "lVhcVm1m1lsc8CVQVTuQzTT7Ay9ncPGUICcxOxP4YVRidTkVmlkvcMCXTFVtDLwJOBJ4C7Bh8dA8\n",
       "4CzyxOzcqMRT5VRoZt3KAd9BVNVU4DCy180uNQ+tBC4HLiCP8G+KSqxof4Vm1k0c8B1IVW1ErnL1\n",
       "WuAAYM8hmzwJ/Jic++Zi98Yxs3oc8F1AVW0NHAi8GXglawf+AuB7wE+AWx32ZjbAAd+FVNXOwAeA\n",
       "Y4BpNQ/dA9wILAYWkc06F0clHmt7kWZWOgd8F1NVE4FZwOHAwcBWdTZbDVxKHuH/OCqxqH0VmlmZ\n",
       "HPA9QlWJXBT8ueRR/c5ks87erD2185XkydoLgCujEk+3uVQzaxMHfI8reuYcTPbOOQSYXPPwcuAK\n",
       "YCHwF7J552rgHrflm3U/B3wfKaYzPpDsdz8L2HWYTZeSQX9VcX01cJdD36y7OOD7mKraBXghuXj4\n",
       "LsBLgJcBz6qz+TIy6G8B7gduB24FbotKLG9LwWa2XhzwtpaiLX9ncgqFlxWXl1P/BO6AB8iwvxW4\n",
       "g+zFU3t5yEf/Zu3ngLdRFaE/nQz6nYBtyOad5xWXjUd5iRXAEga7b9aG/yLgbuDeqMSaVtRv1q8c\n",
       "8DYuRfhvD+wG7A7MIHvx1F42beClVpOBf1dx/TB5LuAO4M7istRz8pg1zgFvLaeqNmfd0J9ec70D\n",
       "8OwGX+4J4BHyB+Dhmr9r71s25LJ84No/ENZPWhrwkmYB3wImAKdGxFfrbPPvZDe+FcDREXFNM4u0\n",
       "7qCqpjAY9tPI+fIH+vMPXLYmv0vj8RgZ+I+TPxYri0vt3yuBR1n3x+OROn8/7vML1qlaFvCSJpA9\n",
       "Lt5A/pP7z8ARETG/ZptDgOMi4hBJ+wAnRMS+zSyy10iaGRFzyq6jDEVz0BSyl8/m/IwDOZQFxe28\n",
       "D6YCWwBbDrkM3DfeH4ih1lA/+B8mf0weLy4DPyJPUP8Hpd7lSeApYNVoPyL9/L0Yyp/FoPFk58RR\n",
       "Ht8bWBARC4sdnQMcCsyv2eZtwPcBIuIKSVMlbRsRS8dSUJ+YCcwpuYZSFCG3orjco9k6Iq6O7zT6\n",
       "/OIHYjMy7DcmfyxqL5OL642L7TYvLs8acl379xTyR2Xq+N/hiLWvBlYVl6fWud6PrVTVXSNuU/+6\n",
       "WdsMu20J/8KZSZ/+P9JMowX8NLJ3xIBFwD4NbDOdPLlm1lRF0AwcYTeFqprEYOgP/THYlPyxqP0x\n",
       "mUz9H5V6l42AScVlYnGZUreQXCZm22a9r2ZSVQE8Tf5r5+khf492Pdo2615eyc6qal9yhbT62+Rl\n",
       "pMej5rr2Uu++sWzTzNcabptLGvsvVN9oAd/or/bQfz64PdO6RlRiFfBgcWmJ4l8eE8kYn1TnehI3\n",
       "8XEO5Ht1Hxv+eY1s04znD9TfHtlpd5dRtuoHHxvPk0f7D7aYPGE2YAfyCH2kbaYX961DkoO/IKlS\n",
       "dg2dwp9FjdkcW3YJHePisgvoCP85niePFvBzgd0kzSAHuRwOHDFkm/OB44BzJO0LPFSv/d0nWM3M\n",
       "2mvEgI+I1ZKOA35D9lw4LSLmSzq2ePzkiPiVpEMkLSB7Gnyg5VWbmdmo2jbQyczM2muD0TcZH0mz\n",
       "JN0s6TZJn231/jqNpIWSrpd0jaQri/u2lPQ7SbdK+q2klnbPK4uk70laKumGmvuGfe+SPld8T26W\n",
       "dFA5VbfGMJ/FbEmLiu/GNZIOrnmslz+LHST9QdJNkm6U9Ini/r77bozwWTTnuxERLbuQzToLyLlN\n",
       "JgHXAnu0cp+ddiHnX9lyyH1fA/6++PuzwL+UXWeL3vv+wEuBG0Z77+Qi5NcW35MZxfdmg7LfQ4s/\n",
       "iwrwN3WvURPAAAACTUlEQVS27fXPYjtgr+LvTcnBlHv043djhM+iKd+NVh/BPzNQKiJWAQMDpfrN\n",
       "0BPMzwwOK67f3t5y2iMi/khOKVBruPd+KHB2RKyKHFi3gPz+9IRhPgtY97sBvf9Z3BsR1xZ/P0YO\n",
       "nJxGH343RvgsoAnfjVYHfL1BUNOG2bZXBXChpLmSPlzcVzvSdykdOrilRYZ779uzdhfcfvmufFzS\n",
       "dZJOq2mS6JvPouih91Jy2cm+/m7UfBaXF3eN+7vR6oD3GVx4dUS8lJyM7a8l7V/7YOS/u/ryc2rg\n",
       "vff653ISOQHbXsA9wDdG2LbnPgtJmwI/Bj4ZEY/WPtZv343is/gR+Vk8RpO+G60O+EYGSvW0iLin\n",
       "uL4f+Cn5z6mlkrYDkPQc4L7yKmy74d57wwPmekVE3BcF4FQG/6nd85+FpElkuJ8VEecVd/fld6Pm\n",
       "s/jBwGfRrO9GqwP+mYFSkjYkB0qd3+J9dgxJG0varPh7E+Ag4AbyM3h/sdn7gfPqv0JPGu69nw/8\n",
       "H0kbStqZXHzkyhLqa5sixAa8g/xuQI9/FpIEnAbMi4hv1TzUd9+N4T6Lpn032nCW+GDyzPAC4HNl\n",
       "n7Vu54X8J9a1xeXGgfdPTnl7Ibn+6W+BqWXX2qL3fzY5Avop8lzMB0Z678DxxffkZuBNZdff4s/i\n",
       "GOBM4HrgOjLMtu2Tz+I15ORa1wLXFJdZ/fjdGOazOLhZ3w0PdDIz61EtH+hkZmblcMCbmfUoB7yZ\n",
       "WY9ywJuZ9SgHvJlZj3LAm5n1KAe8mVmPcsCbmfWo/wWxb/Mr24AihQAAAABJRU5ErkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f24e5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.plot([x['log_loss'] for x in results[0.5]['scores_test']], 'r', linewidth=2)\n",
    "plt.plot([x['log_loss'] for x in results[0.5]['scores_train']], 'g', linewidth=2)\n",
    "plt.legend(['test', 'train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = results[0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best = reduce(lambda a,b : a if a['log_loss'] < b['log_loss'] else b, res['scores_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'log_loss': 0.52971571631359193, 'n_iter': 36}\n",
      "0.53\n"
     ]
    }
   ],
   "source": [
    "print best\n",
    "print '%.2f' % best['log_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier( random_state=241, n_estimators=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, n_estimators=36, n_jobs=1,\n",
       "            oob_score=False, random_state=241, verbose=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54\n"
     ]
    }
   ],
   "source": [
    "print '%.2f' % log_loss(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
